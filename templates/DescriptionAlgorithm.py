import streamlit as st
from PIL import Image

def app():
    # Sidebar menu
    tab1, tab2, tab3 = st.tabs([" # Decision Trees", " # Random Forests", "# K-Medoids"])

    with tab1: 
        # Main content area
        st.header("L‚Äôalgorithme de Decision Trees")
        
        with st.expander('Description', True):
            st.markdown("## 1. Description de l‚Äôalgorithme Decision Trees")

            st.markdown("""
            Les arbres de d√©cision sont des mod√®les d'apprentissage automatique supervis√© qui permettent de prendre des d√©cisions en suivant une s√©rie de r√®gles simples organis√©es de mani√®re hi√©rarchique. Ils sont particuli√®rement appr√©ci√©s pour leur interpr√©tabilit√© et leur capacit√© √† traiter aussi bien des probl√®mes de classification que de r√©gression.
            
            Un arbre de d√©cision se pr√©sente sous forme d'un graphe arborescent o√π:
            - Chaque n≈ìud interne repr√©sente un test sur un attribut
            - Chaque branche repr√©sente un r√©sultat du test
            - Chaque feuille repr√©sente une d√©cision finale (classe ou valeur)
            """)
        
        with st.expander('Caract√©ristiques', True):
            st.markdown("## 2. Caract√©ristiques de Decision Trees")

            st.markdown("""
                - Tree-like structure with nodes and branches  
                - Root node, internal nodes, and leaf nodes  
                - Binary or multi-way splits  
                - Hierarchical decision making process  
                - Handles both numerical and categorical data  
                - No need for feature scaling or normalization  
                - Easy to interpret and visualize  
                - Prone to overfitting if not pruned  
                - Uses impurity measures (e.g., Gini, entropy) for splits  
                - Capable of modeling non-linear relationships  
                - Fast training on small to medium datasets  
                - Sensitive to small changes in data (unstable)
            """)

        with st.expander('Mode de fonctionnement', True):
            st.markdown("## 3. Mode de fonctionnement de Decision Trees")

            st.markdown("### Crit√®res de division pour arbres de d√©cision")

            st.markdown("- **Indice de Gini**: Mesure l'impuret√© d'un n≈ìud")
            st.latex(r"Gini(t) = 1 - \sum_{i=1}^{c} p(i|t)^2")
            st.markdown("o√π $p(i|t)$ est la proportion d'observations de classe $i$ dans le n≈ìud $t$.")

            st.markdown("- **Entropie et Gain d'information**: Mesure de la r√©duction de l'incertitude")
            st.latex(r"Entropie(t) = -\sum_{i=1}^{c} p(i|t) \log_2 p(i|t)")
            st.latex(r"GainInfo(t, a) = Entropie(t) - \sum_{v \in \text{Valeurs}(a)} \frac{|t_v|}{|t|} Entropie(t_v)")

            st.markdown("### Pour les probl√®mes de r√©gression:")

            st.markdown("- **R√©duction de la variance**:")
            st.latex(r"Variance(t) = \frac{1}{N} \sum_{i=1}^{N} (y_i - \bar{y})^2")
            st.latex(r"Reduction(t, a) = Variance(t) - \sum_{v \in \text{Valeurs}(a)} \frac{|t_v|}{|t|} Variance(t_v)")

            st.markdown("### √âlagage (pruning)")
            st.markdown("L'√©lagage est une technique pour r√©duire la complexit√© et √©viter le surapprentissage :")
            st.markdown("- **Pr√©-√©lagage**: Arr√™ter la croissance de l'arbre avant qu'il ne devienne trop sp√©cifique")
            st.markdown("- **Post-√©lagage**: Construire l'arbre complet, puis √©liminer les branches peu significatives")

        with st.expander('Avantages et Inconv√©nients', True):   
            st.markdown("## 4. Avantages et Inconv√©nients")

            st.markdown("### Avantages")
            st.markdown("""
                - Facilement interpr√©tables (mod√®le "bo√Æte blanche")
                - Peu de pr√©paration des donn√©es requise
                - Capable de traiter des donn√©es num√©riques et cat√©gorielles
                - Gestion naturelle des valeurs manquantes
                - Performance calculatoire efficace
            """)

            st.markdown("### Inconv√©nients")
            st.markdown("""
                - Tendance au surapprentissage (overfitting)
                - Instabilit√© (sensibilit√© aux petites variations dans les donn√©es)
                - Biais vers les attributs avec plus de niveaux
            """)
        
        with st.expander('Domaines et champs d\'application', True):
            st.markdown("## 5. Domaines et champs d'application")

            st.markdown("""
                - **Medical diagnosis**
                - **Customer churn prediction**
                - **Credit risk assessment**
                - **Plant or animal species classification**
            """)

    with tab2:
        st.header("L‚Äôalgorithme de For√™ts Al√©atoires (Random Forests)")
        
        with st.expander('Description', True):
            st.markdown("## 1. Description de l‚Äôalgorithme Random Forests")

            st.markdown("""
            Les for√™ts al√©atoires repr√©sentent une avanc√©e majeure dans le domaine de l'apprentissage automatique.
            Elles reposent sur l'id√©e de combiner plusieurs arbres de d√©cision pour am√©liorer la robustesse, 
            la pr√©cision et la capacit√© de g√©n√©ralisation des mod√®les pr√©dictifs. Gr√¢ce √† leur principe de vote majoritaire 
            ou de moyenne des pr√©dictions, elles corrigent efficacement les faiblesses inh√©rentes aux arbres individuels.
            """)
            st.markdown("""
            Une for√™t al√©atoire est un ensemble d'arbres de d√©cision, chacun construit √† partir d'un √©chantillon 
            al√©atoire des donn√©es et d'un sous-ensemble de variables s√©lectionn√©es de mani√®re al√©atoire √† chaque n≈ìud. 
            Ce processus favorise la diversit√© entre les arbres, ce qui r√©duit le risque de surapprentissage.
            """)
        
        with st.expander('Caract√©ristiques', True):
            st.markdown("## 2. Caract√©ristiques de Random Forests")

            st.markdown("""
            - Bagging (Bootstrap Aggregating) : cr√©ation de multiples sous-√©chantillons de donn√©es avec remplacement.
            - S√©lection al√©atoire de variables : √† chaque division d'un n≈ìud, seul un sous-ensemble al√©atoire de caract√©ristiques est test√©.
            - Vote majoritaire (classification) ou moyenne (r√©gression) pour agr√©ger les pr√©dictions.
            """)
        
        with st.expander('Mode de fonctionnement', True):
            st.markdown("## 3. Mode de fonctionnement de Random Forests")

            st.markdown("""
            1. G√©n√©rer plusieurs sous-√©chantillons du jeu de donn√©es d'origine (bootstrap).
            2. Pour chaque sous-√©chantillon, construire un arbre de d√©cision complet sans √©lagage.
            3. √Ä chaque division de l'arbre, choisir al√©atoirement un sous-ensemble de caract√©ristiques.
            4. Agr√©ger les pr√©dictions de tous les arbres :
                - Classification : vote majoritaire
                - R√©gression : moyenne des pr√©dictions
            """)

            st.markdown("### üìä Sch√©mas Illustratifs")
            st.markdown("""
            Le sch√©ma ci-dessous illustre une **for√™t al√©atoire** compos√©e de plusieurs **arbres de d√©cision**,
            dont les r√©sultats sont combin√©s par **vote majoritaire** pour aboutir √† une pr√©diction finale.
            """)

            # Affichage de l'image
            col1, col2 = st.columns(2)
            with col1:
                image0 = Image.open("assets/image0.png")
                small_image0 = image0.resize((600, 400))
                st.image(small_image0, caption="Sch√©ma Visuel de Bagging")

            with col2:
                image = Image.open("assets/image.png")
                small_image = image.resize((600, 400))
                st.image(small_image, caption="Sch√©ma Visuel de la For√™t Al√©atoire")
        
        with st.expander('Avantages et Inconv√©nients', True):
            st.markdown("## 4. Avantages et Inconv√©nients")

            st.markdown("### Avantages")
            st.markdown("""
                - R√©duction du surapprentissage gr√¢ce √† l'agr√©gation.
                - Excellente pr√©cision pour des probl√®mes complexes.
                - G√®re les valeurs manquantes et les variables cat√©gorielles.
                - Capable de d√©tecter l'importance des variables.
            """)
            
            st.markdown("### Inconv√©nients")
            st.markdown("""
                - Moins interpr√©table qu'un arbre de d√©cision unique.
                - Plus co√ªteux en ressources (temps de calcul et m√©moire).
                - Difficile √† d√©ployer sur des syst√®mes temps r√©el en cas de grande for√™t.
            """)
        
        with st.expander('Domaines et champs d\'application', True):
            st.markdown("## 5. Domaines et champs d'application")

            st.markdown("""
                - Financial market prediction
                - Healthcare diagnostics
                - Image classification
                - Remote sensing
            """)

    with tab3:
        st.header("L‚Äôalgorithme de Clustering K-Medoids")

        # Section 1
        with st.expander('Description', True):
            st.markdown("## 1. Description de l‚Äôalgorithme K-Medoids")
            st.write("""
            L‚Äôalgorithme K-Medoids est une m√©thode de clustering dans le cadre de l‚Äôapprentissage non supervis√©. 
            Il permet de diviser un ensemble de donn√©es en k clusters. Contrairement √† l‚Äôalgorithme K-Means, 
            qui utilise des centro√Ødes comme centres des clusters, K-Medoids choisit des points r√©els du jeu 
            de donn√©es comme repr√©sentants des clusters, appel√©s **medoids**.

            Les medoids sont des points du jeu de donn√©es qui minimisent la distance totale √† tous les autres 
            points du m√™me cluster, ce qui les rend plus robustes aux valeurs aberrantes par rapport aux centro√Ødes.
            """)

        # Section 2
        with st.expander('Caract√©ristiques', True):
            st.markdown("## 2. Caract√©ristiques de K-Medoids")
            st.markdown("""
            - **Clustering bas√© sur les distances** : utilisation de mesures comme la distance euclidienne ou Manhattan.  
            - **Robustesse aux outliers** : plus r√©sistant que K-Means.  
            - **Co√ªt √©lev√© en temps** : plus lent que K-Means, surtout pour de gros datasets.  
            - **Algorithme it√©ratif** : convergence apr√®s plusieurs it√©rations.  
            - **Centres = objets r√©els** : contrairement √† K-Means.
            """)

        # Section 3
        with st.expander('Mode de fonctionnement', True):
            st.markdown("## 3. Mode de fonctionnement de K-Medoids")

            st.markdown("### √âtape 1 : Initialisation")
            st.write(" Choisir k points al¬¥eatoires dans l‚Äôensemble de donn¬¥ees comme les m¬¥ edino¬®ƒ±des.")

            st.markdown("### √âtape 2 : Assignation des points")
            st.write("Chaque point $x_i$ est affect√© au medoid $m_j$ le plus proche :")
            st.latex(r"j = \arg\min_{1 \leq j \leq k} d(x_i, m_j)")
            st.write("o√π $d(x_i, m_j)$ est la distance euclidienne ou Manhattan.")

            st.markdown("### √âtape 3 : Mise √† jour (Swap)")
            st.write("Tester les √©changes entre un medoid $m_j$ et un autre point $x_h$, recalculer :")
            st.latex(r"J = \sum_{j=1}^{k} \sum_{x_i \in C_j} d(x_i, m_j)")
            st.write("Si le co√ªt diminue, accepter l‚Äô√©change.")

            st.markdown("### √âtape 4 : Convergence")
            st.write("R√©p√©ter jusqu‚Äô√† stabilisation ou atteinte du nombre d‚Äôit√©rations.")

        # Section 4
        with st.expander('Avantages et Inconv√©nients', True):
            st.markdown("## 4. Avantages et Inconv√©nients")

            st.markdown("### Avantages")
            st.markdown("""
            - R√©sistant aux outliers.  
            - Adapt√© aux donn√©es non num√©riques.  
            - Interpr√©tabilit√© des centres (objets r√©els).
            """)

            st.markdown("### Inconv√©nients")
            st.markdown("""
            - Complexit√© computationnelle √©lev√©e : $O(k(n-k)^2)$  
            - Sensible √† l‚Äôinitialisation.  
            - Moins adapt√© aux tr√®s grands ensembles de donn√©es.
            """)

        # Section 5
        with st.expander('Domaines et champs d\'application', True):
            st.markdown("## 5. Domaines et champs d'application")
            st.markdown("""
            - **Segmentation de march√©**  
            - **Bioinformatique**  
            - **Analyse de texte**  
            - **R√©seaux de capteurs**  
            - **M√©decine**
            """)

